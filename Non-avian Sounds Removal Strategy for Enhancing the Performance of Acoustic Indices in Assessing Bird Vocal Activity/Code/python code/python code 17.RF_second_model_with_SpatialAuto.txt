# 随机森林 对未清洗后的鸟类（终） + 建模后空间自相关检验 python code 17.RF_second_model_with_SpatialAuto
# -*- coding: utf-8 -*-
import os
import tempfile
tempfile.tempdir = r"E:\Temp"
os.environ["JOBLIB_TEMP_FOLDER"] = r"E:\Temp"

from tqdm import tqdm
import pandas as pd
import numpy as np

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.inspection import permutation_importance
from sklearn.neighbors import NearestNeighbors  # kNN 邻接

# =============================
# 可配置参数（空间自相关部分）
# =============================
SITE_COL = "Site"     # 采样点列
COORD_X_COL = "X"     # 位点表中的经度
COORD_Y_COL = "Y"     # 位点表中的纬度
NEIGHBORS_K = 6       # k 近邻个数
N_PERMUTATIONS = 999  # Moran's I 置换次数（双侧）
site_coords_path = r"E:\voice_data\统计分析\随机森林_4\声景类型原数据\绿心公园位点经纬度.xlsx"

# —————————————————————————————————————————————
# 1. 读取数据
data = pd.read_excel(
    r"E:\voice_data\统计分析\随机森林_2\声景类型原数据\随机森林数据_不清洗五大类.xlsx"
)

# 2. 列定义
meta_cols = ["Site", "Date", "Time"]
X_cols = [
    "ACI", "ADI", "AEI", "BIO", "H", "NDSI",
    "Highway Distance", "Internal Road Distance",
    "Sidewalk Distance", "Water Source Distance"
]
Y_col = "Avain Sum"   # 目标变量（按你的表名）

# 3. 拆分 X, Y, meta
X    = data[X_cols].copy()
Y    = data[Y_col].copy()
meta = data[meta_cols].copy()

# 4. 划分训练/测试（保留 meta）
X_train, X_test, y_train, y_test, meta_train, meta_test = train_test_split(
    X, Y, meta, test_size=0.2, random_state=42
)

# 5. 构建随机森林回归模型
rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=-1)

# 6. GridSearchCV 调参（示例调整 max_features）
param_grid = {"max_features": [3, 5]}
grid_search = GridSearchCV(
    rf,
    param_grid,
    cv=3,
    scoring="r2",
    verbose=2,
    n_jobs=-1
)
grid_search.fit(X_train, y_train)

best_model  = grid_search.best_estimator_
best_params = grid_search.best_params_
best_cv_r2  = grid_search.best_score_
print(f"最佳参数：{best_params}，最佳 CV R²：{best_cv_r2:.4f}")

# 7. 测试集评估
y_pred = best_model.predict(X_test)
r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
print(f"\nAvain Sum — R²: {r2:.3f}, MSE: {mse:.3f}")

# 8. Permutation Importance（ΔMSE）
perm = permutation_importance(
    best_model, X_test, y_test,
    n_repeats=10,
    random_state=42,
    n_jobs=-1,
    scoring='neg_mean_squared_error'
)
delta_mse = perm.importances_mean
imp_df = pd.DataFrame({
    "Feature": X_cols,
    "ΔMSE": delta_mse
}).sort_values("ΔMSE", ascending=False)

print("\nAvain Sum 的特征重要性（按 ΔMSE 排序）：")
print(imp_df)

# 9. 写入 Excel（模型结果）
sheets = {
    "GridSearch": pd.DataFrame([{"Param": k, "Value": v} for k, v in best_params.items()] +
                               [{"Param": "best_cv_r2", "Value": best_cv_r2}]),
    "TestMetrics": pd.DataFrame({
        "Metric": ["R2", "MSE"],
        "Value": [r2, mse]
    }),
    "PermImp": imp_df
}

output_file = r"E:\voice_data\统计分析\随机森林_4\声景类型原数据\Avain_Sum_RF_results_未清洗.xlsx"
with pd.ExcelWriter(output_file, engine="openpyxl") as writer:
    for name, df_sheet in tqdm(sheets.items(), desc="Writing Excel Sheets", total=len(sheets)):
        df_sheet.to_excel(writer, sheet_name=name, index=False)

print(f"✅ Avain Sum 分析结果已导出至：{output_file}")

# =======================================================
# 10. 使用最佳参数在全量数据上重训，获得“建模后”残差
# =======================================================
best_model_full = RandomForestRegressor(
    n_estimators=500,
    random_state=42,
    n_jobs=-1,
    **best_params  # 例如 max_features
)
best_model_full.fit(X, Y)
y_hat_all = best_model_full.predict(X)
residual_all = Y.values - y_hat_all

df_all = meta.copy()
df_all["residual"] = residual_all

# =======================================================
# 11. 合并位点坐标（来自你提供的 Excel：Site, X, Y）
# =======================================================
if not os.path.exists(site_coords_path):
    raise FileNotFoundError(f"未找到位点坐标表：{site_coords_path}")

site_xy = pd.read_excel(site_coords_path)
need_cols = {SITE_COL, COORD_X_COL, COORD_Y_COL}
if not need_cols.issubset(set(site_xy.columns)):
    raise ValueError(f"位点表需包含列 {need_cols}，实际列为：{set(site_xy.columns)}")

df_all = df_all.merge(site_xy[[SITE_COL, COORD_X_COL, COORD_Y_COL]], on=SITE_COL, how="left")

# =======================================================
# 12. 按采样点聚合残差（均值），避免同点多时间片伪自相关
# =======================================================
site_resid = (df_all[[SITE_COL, COORD_X_COL, COORD_Y_COL, "residual"]]
              .dropna(subset=[COORD_X_COL, COORD_Y_COL, "residual"])
              .groupby(SITE_COL, as_index=False)
              .agg({COORD_X_COL: "first", COORD_Y_COL: "first", "residual": "mean"}))

if site_resid.shape[0] < 3:
    raise ValueError("有效采样点少于3个，无法进行 Moran's I 检验。")

coords = site_resid[[COORD_X_COL, COORD_Y_COL]].values  # 使用经纬度做 kNN 没问题
x = site_resid["residual"].values
n = x.size

# =======================================================
# 13. 构建 kNN 空间权重矩阵（对称化，二元权重）
# =======================================================
k = min(NEIGHBORS_K, max(1, n - 1))
nn = NearestNeighbors(n_neighbors=k, algorithm="ball_tree").fit(coords)
dist, idx = nn.kneighbors(coords)

W = np.zeros((n, n), dtype=float)
rows = np.repeat(np.arange(n), k)
cols = idx[:, 0:k].reshape(-1)
W[rows, cols] = 1.0
np.fill_diagonal(W, 0.0)
W = np.maximum(W, W.T)  # 对称化

# 兜底：如有孤点，连最近邻
row_sums = W.sum(axis=1)
if np.any(row_sums == 0):
    nn1 = NearestNeighbors(n_neighbors=2, algorithm="ball_tree").fit(coords)
    _, idx1 = nn1.kneighbors(coords)
    for i in np.where(row_sums == 0)[0]:
        j = idx1[i, 1]
        W[i, j] = 1.0
        W[j, i] = 1.0

# =======================================================
# 14. 计算 Moran's I（全局），999 次置换，双侧 p 值
# =======================================================
def morans_I(x, W, n_perm=999, random_state=42):
    rng = np.random.default_rng(random_state)
    x = np.asarray(x, dtype=float)
    xc = x - x.mean()
    S0 = W.sum()
    if S0 <= 0:
        raise ValueError("权重矩阵全零，无法计算 Moran's I。")
    num = xc @ W @ xc
    den = (xc ** 2).sum()
    I_obs = (len(x) / S0) * (num / den)

    perm_I = np.empty(n_perm, dtype=float)
    for b in range(n_perm):
        xp = rng.permutation(xc)
        num_p = xp @ W @ xp
        perm_I[b] = (len(x) / S0) * (num_p / den)

    # 双侧 p 值
    more_extreme = np.sum(np.abs(perm_I) >= np.abs(I_obs))
    p_two_sided = (more_extreme + 1) / (n_perm + 1)
    return I_obs, p_two_sided

I_val, p_val = morans_I(x, W, n_perm=N_PERMUTATIONS, random_state=42)

print("\n===== 空间自相关（建模后残差，按 Site 聚合）=====")
print(f"Moran's I = {I_val:.3f}, p = {p_val:.3f}  (k = {k}, n_sites = {n})")

# =======================================================
# 15. 将空间自相关结果写入 Excel（新表 SpatialAuto）
# =======================================================
spatial_df = pd.DataFrame({
    "Moran_I": [I_val],
    "p_value": [p_val],
    "n_sites": [n],
    "k_neighbors": [k],
    "permutations": [N_PERMUTATIONS]
})
with pd.ExcelWriter(output_file, engine="openpyxl", mode="a", if_sheet_exists="replace") as writer:
    spatial_df.to_excel(writer, sheet_name="SpatialAuto", index=False)

print(f"✅ Moran's I 与 p 已写入工作表 SpatialAuto：{output_file}")

# =======================================================
# 16. （可选）导出按点残差，便于后续 LISA/制图
# =======================================================
# with pd.ExcelWriter(output_file, engine="openpyxl", mode="a", if_sheet_exists="replace") as writer:
#     site_resid.to_excel(writer, sheet_name="SiteResiduals", index=False)
